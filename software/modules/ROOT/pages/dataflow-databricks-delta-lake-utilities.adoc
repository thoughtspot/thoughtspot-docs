= Using Databricks Delta Lake utilities
:page_aliases: /data-integrate/dataflow/dataflow-databricks-delta-lake-utilities.adoc
:experimental:
:linkattrs:

You can use the Databricks Delta Lake client to customize connections in DataFlow.

Requirements to install Databricks Delta Lake

* python 3- 3.6 and above

* python 2- 2.7.9 and above

Follow these steps to install the Databricks Delta Lake client:

. Run pip install databricks-cli using the appropriate version of pip for your Python installation.
+
[source]
----
pip install databricks-cli --user
----
. In case if pip is not present then please use pip3 for installation.
+
[source]
----
pip3 install databricks-cli --user
----
. Create Symlink of dbfs command
+
[source]
----
sudo ln -snf /home/admin/.local/bin/dbfs /usr/bin/dbfs
----
. Before running the  CLI commands, you must set up authentication. To authenticate to the CLI we use a personal access token.
We have REST API to get access token.
+
[source]
----
Curl -H 'Authorization: Bearer AUTH-TOKEN -X POST -d '{ "lifetime_seconds": 100, "comment": "Remotely genarated token" }' https://DBFS-HOST/api/2.0/token/create
----

[NOTE]
====
You must authenticate, to get access to Databricks REST APIs.
 At least one UI generated token required to generate other tokens.
In this command, replace AUTH-TOKEN with UI Generated token and DBFS-HOST with databricks host.
====

Restart the DataFlow service.
[source]
----
#tscli --adv service restart dataflow
----
