= Databricks Delta Lake connection reference
:last_updated: 03/08/2022
:experimental:
:linkattrs:
:page-aliases: /data-integrate/dataflow/dataflow-databricks-delta-lake-reference.adoc, /7.0.0.mar.sw/data-integrate/dataflow/dataflow-databricks-delta-lake-reference.adoc


Learn about the fields used to create Databricks Delta Lake connection with ThoughtSpot DataFlow.

Here is a list of the fields for a Databricks Delta Lake connection in ThoughtSpot DataFlow.
You need specific information to establish a seamless and secure connection.

[#connection-properties]
== Connection properties
[#dataflow-databricks-delta-lake-conn-connection-name]
Connection name:: Name your connection. Mandatory field.
Example:;; AzureDatabricksConnection
[#dataflow-databricks-delta-lake-conn-connection-type]
Connection type:: Choose the Azure Databricks connection type. Mandatory field.
Example:;; Azure Databricks
[#dataflow-databricks-delta-lake-conn-server-hostname-]
Server Hostname:: Specify the hostname of the Databricks server. Mandatory field.
Example:;; www.example.com
[#dataflow-databricks-delta-lake-conn-port]
Port:: Specify the port associated with the system. Mandatory field.
Example:;; 1234
Default:;; 443
[#dataflow-databricks-delta-lake-conn-http-path]
HTTP path:: Specify the HTTP Path. Mandatory field.
Example:;; abcservice
[#dataflow-databricks-delta-lake-conn-protocol]
Protocol:: Specify the remote server connection. Mandatory field.
Example:;; https
Valid Values:;; https, http
Default:;; https
[#dataflow-databricks-delta-lake-conn-cluster-id]
Cluster id:: Specify the canonical identifier for the cluster. Mandatory field.
Example:;; 1234
[#dataflow-databricks-delta-lake-conn-access-token]
Access token:: Specify the access token to authenticate Databricks API. Mandatory field.
Example:;; ABCDEFGH245HIJK
[#dataflow-databricks-delta-lake-conn-dbfs-stage-location]
DBFS stage location:: Specify the mount storage object location. Mandatory field.
Default:;; /dataflow/stage

[#sync-properties]
== Sync properties
[#dataflow-databricks-delta-lake-sync-data-extraction-mode]
Data extraction mode:: Specify the extraction type.
Example:;; JDBC
Valid Values:;; JDBC, Spark API
Default:;; JDBC
[#dataflow-databricks-delta-lake-sync-column-delimiter]
Column delimiter:: Specify the column delimiter character. Mandatory field.
Example:;; 1
Valid Values:;; Any printable ASCII character or decimal value for ASCII character
Default:;; 1
[#dataflow-databricks-delta-lake-sync-enclosing-character]
Enclosing character:: Specify if the text columns in the source data needs to be enclosed in quotes. Optional field.
Example:;; DOUBLE
Valid Values:;; SINGLE, DOUBLE
Default:;; DOUBLE
Other notes:;; This is required if the text data has newline character or delimiter character.
[#dataflow-databricks-delta-lake-sync-escape-character]
Escape character::
Specify this if the text qualifier is mentioned.
This should be the character which escapes the text qualifier character in the source data. Optional field.
Example:;; \"
Valid Values:;; Any ASCII character
Default:;; \"
[#dataflow-databricks-delta-lake-sync-max-ignored-rows]
include::partial$dataflow/max-ignored-rows.adoc[]
[#dataflow-databricks-delta-lake-sync-ts-load-options]
include::partial$dataflow/ts-load-options.adoc[]

'''
> **Related information**
>
> * xref:dataflow-databricks-delta-lake-add.adoc[Add a connection]
> * xref:dataflow-databricks-delta-lake-sync.adoc[Sync data]
