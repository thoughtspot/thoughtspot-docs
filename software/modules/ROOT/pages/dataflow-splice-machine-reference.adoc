= Splice Machine connection reference
:last_updated: 03/17/2021
:experimental:
:linkattrs:
:page-aliases: /data-integrate/dataflow/dataflow-splice-machine-reference.adoc

Learn about the fields used to create a Splice Machine connection with ThoughtSpot DataFlow.

Here is a list of the fields for a Splice Machine connection in ThoughtSpot DataFlow.
You need specific information to establish a seamless and secure connection.

[#connection-properties]
== Connection properties

[#dataflow-splice-machine-conn-connection-name]
Connection name::
  Name your connection. Mandatory field.
  Example;;   SpliceMachineConnection

[#dataflow-splice-machine-conn-connection-type]
Connection type::
  Choose the Splice Machine connection type. Mandatory field.
  Example;;   Splice Machine

[#dataflow-splice-machine-conn-host]
Host::
  Specify the hostname or the IP address of the Splice Machine system Mandatory field.
  Example;;   www.example.com

[#dataflow-splice-machine-conn-port]
Port::
  Specify the port associated with the Splice Machine system Mandatory field.
  Example;;   1234

[#dataflow-splice-machine-conn-user]
User::
Specify the user id that will be used to connect to the Splice Machine system.
This user should have necessary privileges to access the data in the databases. Mandatory field.
  Example;;   userdi

[#dataflow-splice-machine-conn-password]
Password::
include::partial$dataflow/password.adoc[]

[#dataflow-splice-machine-conn-database]
Database::
  Collection of information that is organized so that it can be easily accessed, managed and updated. Mandatory field.
  Example;;   splicedb

[#dataflow-splice-machine-conn-hadoop-version]
Hadoop version::
  Specify the version of Hadoop you are using Mandatory field.
  Example;;   HDP_2.6.4

[#dataflow-splice-machine-sync-hdfs-host]
HDFS host::
  Specify the hostname or the IP address of the HDFS Optional field.
  Example;;   www.example.com
  Other notes;;
Advanced configuration.

[#dataflow-splice-machine-sync-hdfs-port]
HDFS port::
  Specify the port associated to the HDFS Optional field.
  Example;;   1235
  Other notes;;
Advanced configuration.

[#dataflow-splice-machine-sync-hdfs-temp-location]
HDFS temp location::
  Specify the HDFS location for creating temp directory Optional field.
  Example;;   /user/splice/tmp
  Other notes;;
Advanced configuration.

[#dataflow-splice-machine-conn-jdbc-options]
include::partial$dataflow/jdbc-options.adoc[]

[#sync-properties]
== Sync properties
[#dataflow-splice-machine-sync-data-extraction-mode]
Data extraction mode::
  Specify the extraction type. Mandatory field.
  Example:;; JDBC
  Valid Values:;; JDBC, BULK Export
  Default:;; JDBC
[#dataflow-splice-machine-sync-column-delimiter]
Column delimiter::
  Specify the column delimiter character. Mandatory field.
  Example:;; 1
  Valid Values:;; Any printable ASCII character or decimal value for ASCII character
  Default:;; 1
[#dataflow-splice-machine-sync-enclosing-character]
Enclosing character::
  Specify if the text columns in the source data needs to be enclosed in quotes. Optional field.
  Example:;; DOUBLE
  Valid Values:;; SINGLE, DOUBLE
  Default:;; DOUBLE
  Other notes:;; This is required if the text data has newline character or delimiter character.
[#dataflow-splice-machine-sync-escape-character]
Escape character::
  Specify the escape character if using a text qualifier in the source data. Optional field.
  Example:;; \"
  Valid Values:;; Any ASCII character
  Default:;; \"
[#dataflow-splice-machine-sync-fetch-size]
Fetch size::
  Specify the number of rows at a time to fetch and process in memory.
  If you specify zero, the system extracts all rows at once. Optional field.
  Example:;; 1000
  Valid Values:;; Any numeric value
  Default:;; 1000
  Other notes:;; Appears when Extraction Type is "JDBC".
[#dataflow-splice-machine-sync-max-ignored-rows]
include::partial$dataflow/max-ignored-rows.adoc[]

[#dataflow-splice-machine-sync-ts-load-options]
include::partial$dataflow/ts-load-options.adoc[]
