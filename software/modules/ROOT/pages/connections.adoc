= Connections
:last_updated: 08/10/2021
:linkattrs:
:page-partial:
:page-aliases: /data-integrate/embrace/embrace-intro.adoc
:experimental:
:description: Using Connections, you can perform live queries on external databases.

Using Connections, you can perform live queries on external databases.

If your company stores source data externally in data warehouses, you can use ThoughtSpot Connections to directly query that data and use ThoughtSpot's analysis and visualization features, without moving the data into ThoughtSpot.

You can establish direct connections to the following external databases:

[cols="15,~",frame=none,grid=none]
|===
a| image::logo-redshift.png[Amazon Redshift logo] .^a|xref:connections-redshift.adoc[Amazon Redshift (AWS)]
a| image::logo-synapse.png[Azure Synapse logo]  .^a|xref:connections-synapse.adoc[Azure Synapse]
a|  image::logo-databricks.png[Databricks logo] .^a|xref:connections-databricks.adoc[Databricks]
a|  image::logo-denodo.png[Denodo logo] .^a|xref:connections-denodo.adoc[Denodo]
a|  image::logo-dremio.png[Dremio logo] .^a|xref:connections-dremio.adoc[Dremio]
a| image::logo-gcp.png[Google BigQuery logo] .^a|xref:connections-gbq.adoc[Google Big Query]
a| image::logo-oracle.png[Oracle logo] .^a|xref:connections-adw.adoc[Oracle]
a| image::logo-postgresql.png[PostgreSQL logo] .^a|xref:connections-postgresql.adoc[PostgreSQL]
a| image::logo-presto.png[Presto logo] .^a|xref:connections-presto.adoc[Presto]
a| image::logo-sap.png[SAP HANA logo] .^a|xref:connections-hana.adoc[SAP HANA]
a| image::logo-snowflake.png[Snowflake logo] .^a|xref:connections-snowflake.adoc[Snowflake]
a|  image::logo-starburst.png[Starburst logo] .^a|xref:connections-starburst.adoc[Starburst]
a| image::logo-teradata.png[Teradata logo] .^a|xref:connections-teradata.adoc[Teradata]
a| image::logo-trino.png[Trino logo] .^a|xref:connections-trino.adoc[Trino]

|===

== How it works

You create a connection to the external database, choosing the columns from each table that you want to explore in your live query.
Primary key and foreign key relationships are imported along with the primary and foreign key tables.
If there are any joins in the tables of your connection, they are also imported.
After your connection is complete, it becomes a *linked* data source in ThoughtSpot that allows you to query the external database directly.
It's easy to apply transformations and filter the data also.

[#connection-share]
As of the 9.0.0.sw release, users with *can manage data* or *admin* privileges can now share connections with other users or groups that have *can manage data* privileges. Once granted access to a connection, users can add, remove, and modify tables in that connection.


== Key benefits

* Set up and deploy ThoughtSpot faster by connecting directly to the external database.
* Eliminate the need to move data into ThoughtSpot for analysis.
* Centralize data management and governance in the external database.
* Save significant time and money by avoiding ETL pipelines.
* Connect to multiple external databases.

== Recommended instance types

The following sections contain the supported and recommended instance types for direct data connections of ThoughtSpot to deployments in AWS, Azure, and GCP. When setting up your cluster, use the information here to select an instance type, configure the number of instances required for the storage you need, and add data volumes to your cluster.

=== AWS
==== VMs with EBS-only persistent storage

include::partial$aws-ebs-only-storage-connections.adoc[]

==== VMs with EBS and S3 persistent storage

include::partial$aws-ebs-s3-storage-connections.adoc[]

=== Azure

include::partial$azure-storage-connections.adoc[]

=== GCP
==== VMs with Persistent Disk-only storage

include::partial$gcp-persistent-only-storage-connections.adoc[]

==== VMs with Persistent Disk and Google Cloud storage

include::partial$gcp-persistent-cloud-storage-connections.adoc[]

== Limitations

IMPORTANT: ThoughtSpot does not support joins across connections.

=== Feature availability

The following matrix compares the features that are available in our internal high-performance database, Falcon, and the ones available through Connections:

[width="100%",cols="8,1,1",options=header]
|===
| Feature Name | Falcon | Connections

|Simple Search and Complex searches: Versus, Inline Subquerying, Growth
| &#9989;
| &#9989;

| Search Suggestions for column names and values
| &#9989;
| &#9989;

| Headlines that summarize tables
| &#9989;
| &#9989;

| All chart types and configurations
| &#9989;
| &#9989;

| Spot IQ: Analyze
| &#9989;
| &#9989;

| Table and Column remapping through TML files
| &#10060;
| &#9989;

| Custom calendar
| &#9989;
| &#9989;

| Materialized view
| &#9989;
| &#10060;
|===

=== Function availability

The following matrix compares the specific function support across the different databases you can access through Connections.
Functions not listed here have full support.

[width="100%",cols="3,1,1,1,1,1,1",options=header]
|===
| Function | Snowflake | Amazon Redshift | Google BigQuery | Azure Synapse | Teradata | SAP HANA

| `SOUNDS_LIKE`
| &#10060;
| &#10060;
| &#10060;
| &#10060;
| &#10060;
| &#10060;

| `STRING_ MATCH_SCORE`
| &#10060;
| &#10060;
| &#10060;
| &#10060;
| &#10060;
| &#10060;

| `EDIT_DISTANCE_WITH_CAP`
| &#10060;
| &#10060;
| &#10060;
| &#10060;
| &#10060;
| &#10060;

| `APPROX_SET_CARDINALITY`
| &#10060;
| &#10060;
| &#10060;
| &#10060;
| &#10060;
| &#10060;

| `COUNT_NOT_NULL`
| &#10060;
| &#10060;
| &#10060;
| &#10060;
| &#10060;
| &#10060;

| `SPELLS_LIKE`
| &#9989;
| &#10060;
| &#10060;
| &#10060;
| &#9989;
| &#10060;

| `EDIT_DISTANCE`
| &#9989;
| &#10060;
| &#10060;
| &#10060;
| &#9989;
| &#10060;

| `MEDIAN`
| &#9989;
| &#9989;
| &#10060;
| &#9989;
| &#9989;
| &#9989;

| `PERCENTILE`
| &#9989;
| &#9989;
| &#10060;
| &#9989;
| &#9989;
| &#10060;
|===

=== Data type availability

The following matrix captures the specific data type support limitations across the different databases accessible through Connections.
Data types not listed here have full support.

[width="100%",cols="3,1,1,1,1,1,1",options=header]
|===
| Data Type | Snowflake | Amazon Redshift | Google BigQuery | Azure Synapse | Teradata | SAP HANA

| `BINARY`
| &#10060;
| &#9989;
| &#9989;
| &#10060;
| &#9989;
| &#9989;

| `VARBINARY`
| &#10060;
| &#9989;
| &#9989;
| &#10060;
| &#9989;
| &#10060;

| `GEOMETRY`
| &#9989;
| &#10060;
| &#9989;
| &#9989;
| &#9989;
| &#10060;

| `BYTES`
| &#9989;
| &#9989;
| &#10060;
| &#9989;
| &#10060;
| &#9989;

| `DATETIMEOFFSET`
| &#9989;
| &#9989;
| &#9989;
| &#10060;
| &#9989;
| &#9989;
|===

=== Additional specific exceptions

The following list captures the specific limitations across the different databases supported through Connections.
Databases not listed here have full support.

General for all databases::
  Sample values;; ThoughtSpot does not internationalize sample values in tables.

Google BigQuery::
  Join support;;  Google BigQuery does not support PK-FK joins. Therefore, when using Connections, you must create joins explicitly in ThoughtSpot.
  Partitioned tables;;  When running a query on a partitioned table with the *Require partition filter option* enabled, you must specify the `WHERE` clause. Without a `WHERE` clause specified, queries generate an error. To ensure that the query on such tables honors the partition condition, you must create a worksheet filter in ThoughtSpot.

Azure Synapse::
  Azure Synapse supports up to 10 `IF THEN ELSE` statements in a single query.
+
Azure Synapse does not support foreign keys, so no PK-FK joins can be defined in Synapse.

Teradata::
  Teradata does not support the function `AGGREGATE_DISTINCT`.
+
Teradata does not support the following data types: `JSON, INTERVAL, VARBYTE, BLOB, CLOB, PERIOD, XML, GEOSPATIAL`.

SAP HANA::
  SAP HANA does not support the following functions: `PERCENTILE, AGGREGATE_DISTINCT, SPELLS_LIKE, EDIT_DISTANCE`.
+
SAP HANA does not support the following data types: `BLOB, CLOB, NCLOB, TEXT, POINT`.
+
SAP HANA does not support calculation views with mandatory input parameters. If you need to use calculation views in ThoughtSpot, you must remove the mandatory parameter requirement.

== Next steps

* xref:connections-redshift-add.adoc[Add an Amazon Redshift connection]: Create the connection between ThoughtSpot and tables in an Amazon RedShift database.
* xref:connections-synapse-add.adoc[Add an Azure Synapse connection]: Create the connection between ThoughtSpot and tables in an Azure Synapse database.
* xref:connections-databricks-add.adoc[]: Create the connection between ThoughtSpot and tables in a Databricks database.
* xref:connections-dremio-add.adoc[]: Create the connection between ThoughtSpot and tables in a Dremio database.
* xref:connections-gbq-add.adoc[Add a Google BigQuery connection]: Create the connection between ThoughtSpot and tables in a Google BigQuery database.
* xref:connections-adw-add.adoc[Add an Oracle ADW connection]: Create the connection between ThoughtSpot and tables in an Oracle Distributed Warehouse (ODW) database.
* xref:connections-postgresql-add.adoc[]: Create the connection between ThoughtSpot and tables in a PostgreSQL database.
* xref:connections-presto-add.adoc[]: Create the connection between ThoughtSpot and tables in a Presto database.
* xref:connections-hana-add.adoc[Add an SAP HANA connection]: Create the connection between ThoughtSpot and tables in an SAP HANA database.
* xref:connections-snowflake-add.adoc[Add a Snowflake connection]: Create the connection between ThoughtSpot and tables in a Snowflake database.
* xref:connections-starburst-add.adoc[]: Create the connection between ThoughtSpot and tables in a Starburst database.
* xref:connections-teradata-add.adoc[Add a Teradata connection]: Create the connection between ThoughtSpot and tables in a Teradata database.
* xref:connections-trino-add.adoc[Add a Trino connection]: Create the connection between ThoughtSpot and tables in a Trino connection.
