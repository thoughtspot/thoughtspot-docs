= Databricks Delta Lake connection reference
:last_updated: 09/14/2020


Learn about the fields used to create Databricks Delta Lake connection with ThoughtSpot DataFlow.

Here is a list of the fields for an Databricks Delta Lake connection in ThoughtSpot DataFlow.
You need specific information to establish a seamless and secure connection.

== Connection properties
+++<dlentry id="dataflow-databricks-delta-lake-conn-connection-name">+++Connection name:::: Name your connection. Mandatory field. *Example:* + AzureDatabricksConnection+++</dlentry>++++++<dlentry id="dataflow-databricks-delta-lake-conn-connection-type">+++Connection type:::: Choose the Azure Dtabricks connection type. Mandatory field. *Example:* + Azure Databricks+++</dlentry>++++++<dlentry id="dataflow-databricks-delta-lake-conn-server-hostname-">+++Server Hostname:::: Specify the hostname of the Databricks server Mandatory field. *Example:* + www.example.com+++</dlentry>++++++<dlentry id="dataflow-databricks-delta-lake-conn-port">+++Port:::: Specify the port associated with the system. Mandatory field. *Example:* + 1234 *Default:* + 443+++</dlentry>++++++<dlentry id="dataflow-databricks-delta-lake-conn-http-path">+++HTTP path:::: Specify the HTTP Path. Mandatory field. *Example:* + abcservice+++</dlentry>++++++<dlentry id="dataflow-databricks-delta-lake-conn-protocol">+++Protocol:::: Specify the remote server connection Mandatory field. *Example:* + https *Valid Values:* + https, http *Default:* + https+++</dlentry>++++++<dlentry id="dataflow-databricks-delta-lake-conn-cluster-id">+++Cluster id:::: Specify the canonical identifier for the cluster Mandatory field. *Example:* + 1234+++</dlentry>++++++<dlentry id="dataflow-databricks-delta-lake-conn-access-token">+++Access token:::: Specify the access token to authenticate Databricks API. Mandatory field. *Example:* + ABCDEFGH245HIJK+++</dlentry>++++++<dlentry id="dataflow-databricks-delta-lake-conn-dbfs-stage-location">+++DBFS stage location:::: Specify the mount storage object location Mandatory field. *Default:* + /dataflow/stage+++</dlentry>+++

== Sync properties
+++<dlentry id="dataflow-databricks-delta-lake-sync-column-delimiter">+++Column delimiter:::: Specify the column delimiter character. Mandatory field. *Example:* + 1 *Valid Values:* + Any printable ASCII character or decimal value for ASCII character *Default:* + 1+++</dlentry>++++++<dlentry id="dataflow-databricks-delta-lake-sync-enclosing-character">+++Enclosing character:::: Specify if the text columns in the source data needs to be enclosed in quotes. Optional field. *Example:* + DOUBLE *Valid Values:* + SINGLE, DOUBLE *Default:* + DOUBLE *Other notes:* + This is required if the text data has newline character or delimiter character.+++</dlentry>++++++<dlentry id="dataflow-databricks-delta-lake-sync-escape-character">+++Escape character::::
Specify this if the text qualifier is mentioned.
This should be the character which escapes the text qualifier character in the source data. Optional field. *Example:* + \" *Valid Values:* + Any ASCII character *Default:* + \"+++</dlentry>++++++<dlentry id="dataflow-databricks-delta-lake-sync-ts-load-options">+++TS load options::::
Specifies the parameters passed with the `tsload` command, in addition to the commands already included by the application.
The format for these parameters is: + ` --<param_1_name> <optional_param_1_value>` + ` --<param_2_name> <optional_param_2_value>` Optional field. *Example:* + `--max_ignored_rows 0` *Valid Values:* +  + ` --null_value ""` + ` --escape_character ""` + ` --max_ignored_rows 0` *Default:* + ` --max_ignored_rows 0`+++</dlentry>+++
