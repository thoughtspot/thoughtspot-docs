= Sync data through Azure Data Lake connection
:last_updated: 02/19/2021
:linkattrs:
:experimental:

After using ThoughtSpot DataFlow to establish a connection to an Azure Data lake file system, you can create automatic data updates, to seamlessly refresh your data.

include::partial$sync-for-databases.adoc[]

. Specify the sync properties for files:
 ** xref:dataflow-azure-data-lake-reference.adoc#dataflow-azure-data-lake-sync-column-delimiter[Column delimiter] + Specify the column delimiter character.
 ** xref:dataflow-azure-data-lake-reference.adoc#dataflow-azure-data-lake-sync-enclosing-character[Enclosing character] + Specify if the text columns in the source data needs to be enclosed in quotes.
 ** xref:dataflow-azure-data-lake-reference.adoc#dataflow-azure-data-lake-sync-escape-character[Escape character] + Specify this if the text qualifier is mentioned.
This should be the character which escapes the text qualifier character in the source data.
 ** xref:dataflow-azure-data-lake-reference.adoc#dataflow-azure-data-lake-sync-ts-load-options[TS load options] + Specifies the parameters passed with the `tsload` command, in addition to the commands already included by the application.
The format for these parameters is: + ` --<param_1_name> <optional_param_1_value>` + ` --<param_2_name> <optional_param_2_value>`

+
See xref:dataflow-azure-data-lake-reference.adoc#sync-properties[Sync properties] for details, defaults, and examples.
. Save your work by clicking *Save*.
+ Alternatively, click *Save and sync now* to save your work and sync data at the same time.
