= Splice Machine connection reference
:last_updated: 07/7/2020

Learn about the fields used to create a Splice Machine connection with ThoughtSpot DataFlow.

Here is a list of the fields for a Splice Machine connection in ThoughtSpot DataFlow.
You need specific information to establish a seamless and secure connection.

== Connection properties

Connection name:: Name your connection.
+
Mandatory field.
+
*Example:*
+
SpliceMachineConnection

Connection type:: Choose the Splice Machine connection type.
+
Mandatory field.
+
*Example:*
+
Splice Machine

Host:: Specify the hostname or the IP address of the Splice Machine system.
+
Mandatory field.
+
*Example:*
+
www.example.com

Port:: Specify the port associated with the Splice Machine system.
+
Mandatory field.
+
*Example:*
+
1234

User:: Specify the user id that will be used to connect to the Splice Machine system. This user should have necessary privileges to access the data in the databases.
+
Mandatory field.
+
*Example:*
+
userdi

Password:: Specify the password for the user.
+
Mandatory field.
+
*Example:*
+
pswrd234%

Database:: Collection of information that is organized so that it can be easily accessed, managed and updated.
+
Mandatory field.
+
*Example:*
+
splicedb

Hadoop version:: Specify the version of Hadoop you are using.
+
Mandatory field.
+
*Example:*
+
HDP_2.6.4

HDFS host:: Specify the hostname or the IP address of the HDFS.
+
Optional field.
+
*Example:*
+
www.example.com
+
*Other notes:*
+
Advanced configuration

HDFS port:: Specify the port associated to the HDFS.
+
Optional field.
+
*Example:*
+
1235
+
*Other notes:*
+
Advanced configuration

HDFS temp location:: Specify the HDFS location for creating temp directory.
+
Optional field.
+
*Example:*
+
/user/splice/tmp
+
*Other notes:*
+
Advanced configuration

JDBC options:: Specify the options associated with the JDBC URL.
+
Optional field.
+
*Example:*
+
`jdbc:sqlserver://[serverName[\instanceName][:portNumber]]`
+
*Other notes:*
+
Advanced configuration

== Sync properties

Data extraction mode:: Specify the extraction type.
+
Mandatory field.
+
*Example:*
+
JDBC
+
*Valid Values:*
+
JDBC, BULK Export
+
*Default:*
+
JDBC

Column delimiter:: Specify the column delimiter character.
+
Mandatory field.
+
*Example:*
+
1
+
*Valid Values:*
+
Any printable ASCII character or decimal value for ASCII character
+
*Default:*
+
1

Enclosing character:: Specify if the text columns in the source data needs to be enclosed in quotes.
+
Optional field.
+
*Example:*
+
DOUBLE
+
*Valid Values:*
+
SINGLE, DOUBLE
+
*Default:*
+
DOUBLE
+
*Other notes:*
+
This is required if the text data has newline character or delimiter character.

Escape character:: Specify the escape character if using a text qualifier in the source data.
+
Optional field.
+
*Example:*
+
\"
+
*Valid Values:*
+
Any ASCII character
+
*Default:*
+
\"

Fetch size:: Specify the number of rows at a time to fetch and process in memory. If you specify zero, the system extracts all rows at once.
+
Mandatory field.
+
*Example:*
+
1000
+
*Valid Values:*
+
Any numeric value
+
*Default:*
+
1000

TS load options:: Specifies the parameters passed with the `tsload` command, in addition to the commands already included by the application. The format for these parameters is:
+
` --<param_1_name> <optional_param_1_value>`
+
` --<param_2_name> <optional_param_2_value>`
+
Optional field.
+
*Example:*
+
--max_ignored_rows 0
+
*Valid Values:*
+
--user "dbuser" --password "$DIWD" --target_database "ditest" --target_schema "falcon_schema"
+
*Default:*
+
--max_ignored_rows 0
