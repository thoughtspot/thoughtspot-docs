= DataFlow requirements and guidelines
:last_updated: 02/04/2021
:linkattrs:
:experimental:
:redirect_from: /data-integrate/dataflow/dataflow-best-practices.html

Here are some requirements and guidelines for working with DataFlow.

== Requirements

[options="interactive"]
.Your organization has the following setup:
* [ ] Access ThoughtSpot Dataflow at `https://thoughtspot.<customerName>.com/dataflow/`.
* [ ] Minimum disk space allocation of approximately 5 GB in the `/etc/thoughtspot/` directory.

== Guidelines

* Some data sources, such as Snowflake, Amazon S3, Google Cloud Storage, and Azure Blob Storage, temporarily store data as local files before loading into the internal ThoughtSpot database.
These sources require additional disk space, depending on how much data is in the source.
* The DataFlow TQL editor supports the following commands:
 ** `ALTER TABLE`: rename, add, and remove columns.
Modify column datatypes.
Add and remove primary and foreign keys.
 ** `CREATE DATABASE`
 ** `CREATE SCHEMA`
 ** `DELETE FROM <table> [WHERE...]`
 ** `UPDATE <table> ... SET ... [WHERE ...]`

For details on these TQL commands, see the xref:sql-cli-commands.adoc[TQL reference].
