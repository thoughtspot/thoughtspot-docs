= Add a Hive database connection
:last_updated: 7/6/2020

You can add a connection to a Hive database using ThoughtSpot DataFlow.

Follow these steps:

include::partial$add-database-connection.adoc[]

. After you select the Hive *Connection type*, the rest of the connection properties appear.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-connection-name[Connection name]
 +
Name your connection.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-connection-type[Connection type]
 +
Choose the Hive connection type.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-hiveserver2-ha-configured[HiveServer2 HA configured]
 +
Specify this option if using HiveServer2 High Availability.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-hiveserver2-zookeeper-namespace[HiveServer2 zookeeper namespace]
 +
Specify zookeeper namespace as hivesever2.
This is the default value.
Only when using Hiveserver2 HA.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-host[Host]
 +
Specify the hostname or the IP address of the Hadoop system Only when _not_ using Hiveserver2 HA.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-port[Port] + Specify the port.
Only when _not_ using Hiveserver2 HA.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-hive-security-authentication[Hive security authentication]
 +
Specifies the type of security protocol to connect to the instance.
Based on the type of security select the authentication type and provide details.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-user[User]
 +
Specify the user to connect to Hive. This user must have data access privileges.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-password[Password]
 +
Specify the password.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-trust-store[Trust store]
 +
Specify the trust store name for authentication For SSL and Kerberos authentication only.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-trust-store-password[Trust store password]
 +
Specify the password for the trust store For SSL and Kerberos authentication only.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-hive-transport-mode[Hive transport mode]
 +
Applicable only for hive process engine. This specifies the network protocol used for communicating between hive nodes.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-http-path[HTTP path]
 +
This is specified as an option when http transport mode is selected For HTTP transport mode only.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-hadoop-distribution-[Hadoop distribution]
 +
Provide the Hadoop distribution of the connection
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-distribution-version[Distribution version]
 +
Provide the version of the Hadoop distribution
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-hadoop-conf-path[Hadoop conf path]
 +
By default, the system picks the Hadoop configuration files from the HDFS. To override, specify an alternate location.
Applies only when using configuration settings that are different from global Hadoop instance settings.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-dfs-ha-configured[DFS HA configured]
 +
Specify if using High Availability for DFS.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-dfs-name-service[DFS name service]
 +
Specify the logical name of the HDFS nameservice.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-dfs-name-node-ids[DFS name node IDs]
 +
Specify a comma-separated list of NameNode IDs. System uses this property to determine all NameNodes in the cluster.
XML property name is `dfs.ha.namenodes.dfs.nameservices`.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-rpc-address-for-namenode1[RPC address for namenode1]
 +
Specify the fully-qualified RPC address for each listed NameNode. Defined as `dfs.namenode.rpc-address.dfs.nameservices.name node ID 1`.
For DFS HA and Hadoop Extract only.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-rpc-address-for-namenode2[RPC address for namenode2]
 +
Specify the fully-qualified RPC address for each listed NameNode. Define as `dfs.namenode.rpc-address.dfs.nameservices.name node ID 2`.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-dfs-host[DFS host]
 +
Specify the DFS hostname or the IP address.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-dfs-port[DFS port]
 +
Specify the associated DFS port.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-default-dfs-location[Default DFS location]
 +
Specify the location for the default source/target location.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-temp-dfs-location[Temp DFS location]
 +
Specify the location for creating temp directory.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-dfs-security-authentication[DFS security authentication]
 +
Select the type of security being enabled.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-hadoop-rpc-protection[Hadoop RPC protection]
 +
Hadoop cluster administrators control the quality of protection using the configuration parameter `hadoop.rpc.protection`.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-hive-principal[Hive principal]
 +
Principal for authenticating hive services
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-user-principal[User principal]
 +
To authenticate via a key-tab you must have supporting key-tab file which is generated by Kerberos Admin and also requires the user principal associated with Key-tab (Configured while enabling Kerberos)
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-user-keytab[User keytab]
 +
To authenticate via a key-tab you must have supporting key-tab file which is generated by Kerberos Admin and also requires the user principal associated with Key-tab (Configured while enabling Kerberos)
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-kdc-host[KDC host]
 +
Specify KDC Host Name where as KDC (Kerberos Key Distribution Center) is a service than runs on a domain controller server role (Configured from Kerbores configuration-/etc/krb5.conf)
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-default-realm[Default realm]
 +
A Kerberos realm is the domain over which a Kerberos authentication server has the authority to authenticate a user, host or service (Configured from Kerbores configuration-/etc/krb5.conf )
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-queue-name[Queue name]
 +
Specify the queue name followed by a coma separated form in yarn.scheduler.capacity.root.queues. For Hadoop Extract only.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-yarn-web-ui-port[YARN web UI port]
 +
Yarn Providing web UI for yarn RM and by default 8088 in use For Hadoop Extract only.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-zookeeper-quorum-host[Zookeeper quorum host]
 +
Specify the value of hadoop.registry.zk.quorum from yarn-site.xml Only when _not_ using Hiveserver2 HA.
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-yarn-timeline-webapp-host[Yarn timeline webapp host]
 +
Specify the ip adress of yarn timeline service web application
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-yarn-timeline-webapp-port[Yarn timeline webapp port]
 +
Specify the port associated with the yarn timeline service web application
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-yarn-timeline-webapp-version[Yarn timeline webapp version]
 +
Specify the version associated with the yarn timeline service web application
 ** xref:dataflow-hive-reference.adoc#dataflow-hive-conn-jdbc-options[JDBC options]
 +
Specify the options associated with the JDBC URL.

+
See xref:dataflow-hive-reference.adoc#connection-properties[Connection properties] for details, defaults, and examples.
. Click *Create connection*.
