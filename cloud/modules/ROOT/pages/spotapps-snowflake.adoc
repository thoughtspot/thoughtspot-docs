= {spotapp}
:last_updated: 6/13/2022
:experimental:
:linkattrs:
:page-layout: default-cloud
:description: Deploy the Snowflake Performance and Consumption SpotApp, an out-of-the-box solution template built specifically for Snowflake.
:spotapp: Snowflake Performance and Consumption SpotApp
:application: Snowflake

include::partial$spotapps-intro.adoc[]

This is a sample Liveboard, created after you deploy the {spotapp}:

image::spotapp-snowflake-liveboard.png[Snowflake SpotApp Liveboard]

Use the {spotapp} to manage Snowflake costs and investigate query performance. Track how and where your users consume credits, and triage and resolve any performance bottlenecks.

[#prerequisites]
== Prerequisites
Before you can deploy the {spotapp}, you must complete the following prerequisites:

* Review the <<schema,required tables and columns>> for the SpotApp.
* Ensure that your columns match the required column type listed in the schema for your SpotApp.
* Sync all tables and columns from {application} to your cloud data warehouse. You can sync only the required tables and columns, but ThoughtSpot recommends syncing all tables and columns from {application} to your CDW. The columns can be {application}'s out-of-the-box columns, or any custom columns that you are using instead of the out-of-the-box columns.
+
NOTE: If you are using an ETL/ELT tool or working with another team in your organization to move data, our recommendation is that you sync *_all_* columns from the tables listed in the SpotApp.
* Obtain credentials and *SYSADMIN* privileges to connect to your {application} environment. Your {application} environment must contain the data you would like ThoughtSpot to use to create Answers, Liveboards, and Worksheets. Refer to the connection reference for xref:connections-snowflake-reference.adoc[Snowflake] for information about required credentials.
* The connection name for each new SpotApp must be unique.
* `ACCOUNTADMIN` access to {application}.
* Access to the SNOWFLAKE database in your {application} environment.
* Access to the following {application} tables in your {application} environment. Refer to <<schema,{spotapp} schema>> for more details.
** DATABASE_STORAGE_USAGE_HISTORY
** QUERY_HISTORY
** STAGES
** STORAGE_USAGE
** WAREHOUSE_METERING_HISTORY
* Run the required SQL commands in your cloud data warehouse. Refer to <<sql,Run SQL commands>>. Note that you have two options to set up the SpotApp; only choose one of the options.

[#sql]
=== Run SQL commands
You can set up the SpotApp in one of two ways:

* *Option 1:* Copy the data from the SNOWFLAKE database to a different database using {application} tasks. This option has faster performance and a customizable cost. Refer to <<option-1,Option 1 SQL commands>>.
* *Option 2:* Query on the system database directly. This option has slower performance and may be more expensive. Refer to <<option-2,Option 2 SQL commands>>.

[#option-1]
==== Option 1
The following SQL commands grant permission for the role you use in your {application} connection to use the {application} database. They create a separate database and schema for the data in the {application} database, and create the tables with the data. Then, they grant permission for the role you use in your {application} connection to use the {application} database. Replace `<YOUR_ROLE>` and `<YOUR_WAREHOUSE>` with your specific information. The role should be either ACCOUNTADMIN or a custom SpotApps role. You can also modify the schedule. The following commands set the schedule to refresh the table data monthly. Changing the schedule may have performance and cost implications.

NOTE: ThoughtSpot recommends you create the database and schema with the suggested names, using the first two commands in the SQL script. However, you can also use your own names. If you use different names, you must replace ThoughtSpot's suggested names with the names you used.

Run these commands as the `ACCOUNTADMIN`. If you don't have account admin access, you can create a custom role with the permissions required to execute tasks. See the https://docs.snowflake.com/en/user-guide/tasks-intro#task-security[Snowflake documentation^].

Make sure to be consistent in your SQL script. If you use double quotes as object identifiers for one object, you must use double quotes for all objects. If you run all the commands at once, use semicolons to separate the commands.

SQL commands:
[%collapsible]
.Open the dropdown menu to view the SQL commands.
====
--
include::partial$snowflake-sql-script-option-1.adoc[]
--
====

[#option-2]
==== Option 2
The following SQL commands grant permission for the role you use in your {application} connection to use the {application} database. They prepare you to query on the system database directly. Replace *YOUR_ROLE* with your specific information, either the ACCOUNTADMIN or a custom SpotApps role.

Run these commands as the `ACCOUNTADMIN`. If you don't have account admin access, you can create a custom role with the permissions required to execute tasks. See the https://docs.snowflake.com/en/user-guide/tasks-intro#task-security[Snowflake documentation^].

Make sure to be consistent in your SQL script. If you use double quotes as object identifiers for one object, you must use double quotes for all objects. If you run all the commands at once, use semicolons to separate the commands.

SQL commands:
[%collapsible]
.Open the dropdown to view the SQL commands.
====
--
include::partial$snowflake-sql-script-option-2.adoc[]
--
====

include::partial$spotapp-deploy-individual.adoc[]

[#schema]
== {spotapp} schema

The following table describes the schema for the {spotapp}.

|===
| Table | Column name | Column type | Required column

| QUERY_HISTORY | QUERY_ID| VARCHAR | Y
| QUERY_HISTORY | QUERY_TEXT| VARCHAR | Y
| QUERY_HISTORY | DATABASE_ID | NUMBER| Y
| QUERY_HISTORY | DATABASE_NAME | VARCHAR | Y
| QUERY_HISTORY | SCHEMA_ID | NUMBER| N
| QUERY_HISTORY | SCHEMA_NAME | VARCHAR | Y
| QUERY_HISTORY | QUERY_TYPE| VARCHAR | Y
| QUERY_HISTORY | SESSION_ID| NUMBER| N
| QUERY_HISTORY | USER_NAME | VARCHAR | Y
| QUERY_HISTORY | ROLE_NAME | VARCHAR | Y
| QUERY_HISTORY | WAREHOUSE_ID| NUMBER| Y
| QUERY_HISTORY | WAREHOUSE_NAME| VARCHAR | Y
| QUERY_HISTORY | WAREHOUSE_SIZE| VARCHAR | Y
| QUERY_HISTORY | WAREHOUSE_TYPE| VARCHAR | N
| QUERY_HISTORY | QUERY_TAG | VARCHAR | N
| QUERY_HISTORY | EXECUTION_STATUS| VARCHAR | N
| QUERY_HISTORY | ERROR_CODE| VARCHAR | Y
| QUERY_HISTORY | ERROR_MESSAGE | VARCHAR | Y
| QUERY_HISTORY | START_TIME| TIMESTAMP | Y
| QUERY_HISTORY | ROWS_PRODUCED | NUMBER| N
| QUERY_HISTORY | PARTITIONS_SCANNED| NUMBER| N
| QUERY_HISTORY | PARTITIONS_TOTAL| NUMBER| N
| QUERY_HISTORY | PERCENTAGE_SCANNED_FROM_CACHE | FLOAT | N
| QUERY_HISTORY | BYTES_SPILLED_TO_LOCAL_STORAGE| NUMBER| N
| QUERY_HISTORY | BYTES_SPILLED_TO_REMOTE_STORAGE | NUMBER| N
| QUERY_HISTORY | QUEUED_REPAIR_TIME| NUMBER| Y
| QUERY_HISTORY | QUEUED_OVERLOAD_TIME| NUMBER| Y
| QUERY_HISTORY | QUEUED_PROVISIONING_TIME| NUMBER| Y
| QUERY_HISTORY | TOTAL_ELAPSED_TIME| NUMBER| Y
| QUERY_HISTORY | COMPILATION_TIME| NUMBER| N
| QUERY_HISTORY | EXECUTION_TIME| NUMBER| Y
| WAREHOUSE_METERING_HISTORY| WAREHOUSE_ID| NUMBER| Y
| WAREHOUSE_METERING_HISTORY| WAREHOUSE_NAME| VARCHAR | Y
| WAREHOUSE_METERING_HISTORY| START_TIME| TIMESTAMP | Y
| WAREHOUSE_METERING_HISTORY| CREDITS_USED| NUMBER| Y
| WAREHOUSE_METERING_HISTORY| CREDITS_USED_COMPUTE| NUMBER| Y
| WAREHOUSE_METERING_HISTORY| CREDITS_USED_CLOUD_SERVICES | NUMBER| Y
| WAREHOUSE_METERING_HISTORY| END_TIME| TIMESTAMP | N
| STAGES| STAGE_ID| NUMBER| N
| STAGES| STAGE_NAME| VARCHAR | Y
| STAGES| STAGE_SCHEMA_ID | NUMBER| N
| STAGES| STAGE_SCHEMA| VARCHAR | Y
| STAGES| STAGE_CATALOG_ID| NUMBER| N
| STAGES| STAGE_CATALOG | VARCHAR | Y
| STAGES| STAGE_TYPE| VARCHAR | Y
| STAGES| STAGE_OWNER | VARCHAR | Y
| STAGES| DELETED | TIMESTAMP | Y
| STORAGE_USAGE | USAGE_DATE| DATE| Y
| STORAGE_USAGE | FAILSAFE_BYTES| NUMBER| Y
| STORAGE_USAGE | STAGE_BYTES | NUMBER| Y
| STORAGE_USAGE | STORAGE_BYTES | NUMBER| Y
| DATABASE_STORAGE_USAGE_HISTORY| USAGE_DATE| DATE| Y
| DATABASE_STORAGE_USAGE_HISTORY| DATABASE_ID | NUMBER| Y
| DATABASE_STORAGE_USAGE_HISTORY| DATABASE_NAME | VARCHAR | Y
| DATABASE_STORAGE_USAGE_HISTORY| DELETED | TIMESTAMP | Y
| DATABASE_STORAGE_USAGE_HISTORY| AVERAGE_DATABASE_BYTES| FLOAT | Y
| DATABASE_STORAGE_USAGE_HISTORY| AVERAGE_FAILSAFE_BYTES| FLOAT | Y

|===
